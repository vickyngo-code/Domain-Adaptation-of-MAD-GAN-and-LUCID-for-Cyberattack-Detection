2022-11-12 23:41:25.304555: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-12 23:41:25.413757: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-11-12 23:41:25.439049: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-12 23:41:25.917532: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-12 23:41:25.917612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-12 23:41:25.917620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.

Current dataset folder:  ./cic-processed-data/training_history_round_1/
2022-11-12 23:41:30.068585: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2022-11-12 23:41:30.068641: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ws103a-z41387
2022-11-12 23:41:30.068657: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ws103a-z41387
2022-11-12 23:41:30.068855: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 520.61.5
2022-11-12 23:41:30.068898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5
2022-11-12 23:41:30.068912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 520.61.5
2022-11-12 23:41:30.069311: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "IDS201X-LUCID"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv0 (Conv2D)              (None, 98, 1, 64)         2176      
                                                                 
 dropout (Dropout)           (None, 98, 1, 64)         0         
                                                                 
 activation (Activation)     (None, 98, 1, 64)         0         
                                                                 
 mp0 (MaxPooling2D)          (None, 32, 1, 64)         0         
                                                                 
 flatten (Flatten)           (None, 2048)              0         
                                                                 
 fc1 (Dense)                 (None, 1)                 2049      
                                                                 
=================================================================
Total params: 4,225
Trainable params: 4,225
Non-trainable params: 0
_________________________________________________________________
None
/home/zvd0712/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)
Epoch: 1/50
379/379 - 12s - loss: 0.4379 - accuracy: 0.8365 - val_loss: 0.4485 - val_accuracy: 0.8444 - 12s/epoch - 33ms/step
Epoch: 2/50
379/379 - 12s - loss: 0.3980 - accuracy: 0.8497 - val_loss: 0.4284 - val_accuracy: 0.8539 - 12s/epoch - 32ms/step
Epoch: 3/50
379/379 - 12s - loss: 0.3811 - accuracy: 0.8583 - val_loss: 0.4121 - val_accuracy: 0.8587 - 12s/epoch - 31ms/step
Epoch: 4/50
379/379 - 12s - loss: 0.3741 - accuracy: 0.8618 - val_loss: 0.4083 - val_accuracy: 0.8650 - 12s/epoch - 31ms/step
Epoch: 5/50
379/379 - 12s - loss: 0.3682 - accuracy: 0.8646 - val_loss: 0.3956 - val_accuracy: 0.8657 - 12s/epoch - 31ms/step
Epoch: 6/50
379/379 - 12s - loss: 0.3647 - accuracy: 0.8663 - val_loss: 0.3969 - val_accuracy: 0.8653 - 12s/epoch - 31ms/step
Epoch: 7/50
379/379 - 12s - loss: 0.3608 - accuracy: 0.8675 - val_loss: 0.3903 - val_accuracy: 0.8666 - 12s/epoch - 31ms/step
Epoch: 8/50
379/379 - 12s - loss: 0.3571 - accuracy: 0.8685 - val_loss: 0.3872 - val_accuracy: 0.8680 - 12s/epoch - 32ms/step
Epoch: 9/50
379/379 - 12s - loss: 0.3541 - accuracy: 0.8693 - val_loss: 0.3837 - val_accuracy: 0.8684 - 12s/epoch - 31ms/step
Epoch: 10/50
379/379 - 12s - loss: 0.3521 - accuracy: 0.8704 - val_loss: 0.3787 - val_accuracy: 0.8690 - 12s/epoch - 31ms/step
Epoch: 11/50
379/379 - 12s - loss: 0.3489 - accuracy: 0.8711 - val_loss: 0.3779 - val_accuracy: 0.8808 - 12s/epoch - 31ms/step
Epoch: 12/50
379/379 - 12s - loss: 0.3445 - accuracy: 0.8722 - val_loss: 0.3650 - val_accuracy: 0.8799 - 12s/epoch - 32ms/step
Epoch: 13/50
379/379 - 12s - loss: 0.3389 - accuracy: 0.8737 - val_loss: 0.3683 - val_accuracy: 0.8809 - 12s/epoch - 32ms/step
Epoch: 14/50
379/379 - 12s - loss: 0.3337 - accuracy: 0.8756 - val_loss: 0.3582 - val_accuracy: 0.8827 - 12s/epoch - 31ms/step
Epoch: 15/50
379/379 - 12s - loss: 0.3274 - accuracy: 0.8786 - val_loss: 0.3597 - val_accuracy: 0.8817 - 12s/epoch - 31ms/step
Epoch: 16/50
379/379 - 12s - loss: 0.3203 - accuracy: 0.8816 - val_loss: 0.3494 - val_accuracy: 0.8825 - 12s/epoch - 31ms/step
Epoch: 17/50
379/379 - 12s - loss: 0.3151 - accuracy: 0.8850 - val_loss: 0.3396 - val_accuracy: 0.8827 - 12s/epoch - 31ms/step
Epoch: 18/50
379/379 - 12s - loss: 0.3072 - accuracy: 0.8895 - val_loss: 0.3328 - val_accuracy: 0.8839 - 12s/epoch - 31ms/step
Epoch: 19/50
379/379 - 12s - loss: 0.2989 - accuracy: 0.8946 - val_loss: 0.3412 - val_accuracy: 0.8901 - 12s/epoch - 31ms/step
Epoch: 20/50
379/379 - 12s - loss: 0.2939 - accuracy: 0.8994 - val_loss: 0.3267 - val_accuracy: 0.9048 - 12s/epoch - 31ms/step
Epoch: 21/50
379/379 - 12s - loss: 0.2876 - accuracy: 0.9048 - val_loss: 0.3192 - val_accuracy: 0.9457 - 12s/epoch - 31ms/step
Epoch: 22/50
379/379 - 12s - loss: 0.2832 - accuracy: 0.9089 - val_loss: 0.3065 - val_accuracy: 0.9041 - 12s/epoch - 31ms/step
Epoch: 23/50
379/379 - 12s - loss: 0.2765 - accuracy: 0.9143 - val_loss: 0.3036 - val_accuracy: 0.9042 - 12s/epoch - 31ms/step
Epoch: 24/50
379/379 - 12s - loss: 0.2717 - accuracy: 0.9183 - val_loss: 0.3011 - val_accuracy: 0.9829 - 12s/epoch - 31ms/step
Epoch: 25/50
379/379 - 13s - loss: 0.2666 - accuracy: 0.9223 - val_loss: 0.2870 - val_accuracy: 0.9036 - 13s/epoch - 33ms/step
Epoch: 26/50
379/379 - 13s - loss: 0.2619 - accuracy: 0.9258 - val_loss: 0.2874 - val_accuracy: 0.9303 - 13s/epoch - 33ms/step
Epoch: 27/50
379/379 - 13s - loss: 0.2557 - accuracy: 0.9300 - val_loss: 0.2804 - val_accuracy: 0.9502 - 13s/epoch - 33ms/step
Epoch: 28/50
379/379 - 13s - loss: 0.2503 - accuracy: 0.9334 - val_loss: 0.2729 - val_accuracy: 0.9741 - 13s/epoch - 33ms/step
Epoch: 29/50
379/379 - 12s - loss: 0.2475 - accuracy: 0.9349 - val_loss: 0.2796 - val_accuracy: 0.9908 - 12s/epoch - 33ms/step
Epoch: 30/50
379/379 - 13s - loss: 0.2457 - accuracy: 0.9362 - val_loss: 0.2816 - val_accuracy: 0.9338 - 13s/epoch - 33ms/step
Epoch: 31/50
379/379 - 13s - loss: 0.2527 - accuracy: 0.9334 - val_loss: 0.2751 - val_accuracy: 0.9586 - 13s/epoch - 33ms/step
Epoch: 32/50
379/379 - 12s - loss: 0.2462 - accuracy: 0.9368 - val_loss: 0.2592 - val_accuracy: 0.9709 - 12s/epoch - 33ms/step
Epoch: 33/50
379/379 - 13s - loss: 0.2406 - accuracy: 0.9389 - val_loss: 0.2643 - val_accuracy: 0.9884 - 13s/epoch - 33ms/step
Epoch: 34/50
379/379 - 13s - loss: 0.2467 - accuracy: 0.9374 - val_loss: 0.2543 - val_accuracy: 0.9656 - 13s/epoch - 33ms/step
Epoch: 35/50
379/379 - 13s - loss: 0.2355 - accuracy: 0.9424 - val_loss: 0.2424 - val_accuracy: 0.9849 - 13s/epoch - 33ms/step
Epoch: 36/50
379/379 - 13s - loss: 0.2311 - accuracy: 0.9436 - val_loss: 0.2491 - val_accuracy: 0.9901 - 13s/epoch - 33ms/step
Epoch: 37/50
379/379 - 12s - loss: 0.2346 - accuracy: 0.9430 - val_loss: 0.2414 - val_accuracy: 0.9781 - 12s/epoch - 33ms/step
Epoch: 38/50
379/379 - 13s - loss: 0.2330 - accuracy: 0.9436 - val_loss: 0.2383 - val_accuracy: 0.9743 - 13s/epoch - 33ms/step
Epoch: 39/50
379/379 - 13s - loss: 0.2268 - accuracy: 0.9466 - val_loss: 0.2294 - val_accuracy: 0.9427 - 13s/epoch - 33ms/step
Epoch: 40/50
379/379 - 13s - loss: 0.2238 - accuracy: 0.9476 - val_loss: 0.2276 - val_accuracy: 0.9544 - 13s/epoch - 33ms/step
Epoch: 41/50
379/379 - 13s - loss: 0.2249 - accuracy: 0.9474 - val_loss: 0.2277 - val_accuracy: 0.9705 - 13s/epoch - 33ms/step
Epoch: 42/50
379/379 - 12s - loss: 0.2184 - accuracy: 0.9500 - val_loss: 0.2427 - val_accuracy: 0.9021 - 12s/epoch - 33ms/step
Epoch: 43/50
379/379 - 12s - loss: 0.2226 - accuracy: 0.9479 - val_loss: 0.2216 - val_accuracy: 0.9776 - 12s/epoch - 33ms/step
Epoch: 44/50
379/379 - 13s - loss: 0.2186 - accuracy: 0.9502 - val_loss: 0.2208 - val_accuracy: 0.9668 - 13s/epoch - 33ms/step
Epoch: 45/50
379/379 - 13s - loss: 0.2112 - accuracy: 0.9523 - val_loss: 0.2213 - val_accuracy: 0.9332 - 13s/epoch - 34ms/step
Epoch: 46/50
379/379 - 13s - loss: 0.2104 - accuracy: 0.9528 - val_loss: 0.2059 - val_accuracy: 0.9751 - 13s/epoch - 33ms/step
Epoch: 47/50
379/379 - 13s - loss: 0.2062 - accuracy: 0.9539 - val_loss: 0.2102 - val_accuracy: 0.9901 - 13s/epoch - 33ms/step
Epoch: 48/50
379/379 - 13s - loss: 0.2086 - accuracy: 0.9531 - val_loss: 0.2017 - val_accuracy: 0.9833 - 13s/epoch - 33ms/step
Epoch: 49/50
379/379 - 12s - loss: 0.2047 - accuracy: 0.9548 - val_loss: 0.2048 - val_accuracy: 0.9509 - 12s/epoch - 33ms/step
Epoch: 50/50
379/379 - 12s - loss: 0.2086 - accuracy: 0.9535 - val_loss: 0.2036 - val_accuracy: 0.9913 - 12s/epoch - 33ms/step
1346/1346 [==============================] - 3s 3ms/step
Model: "IDS201X-LUCID"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv0 (Conv2D)              (None, 98, 1, 64)         2176      
                                                                 
 dropout (Dropout)           (None, 98, 1, 64)         0         
                                                                 
 activation (Activation)     (None, 98, 1, 64)         0         
                                                                 
 mp0 (MaxPooling2D)          (None, 32, 1, 64)         0         
                                                                 
 flatten (Flatten)           (None, 2048)              0         
                                                                 
 fc1 (Dense)                 (None, 1)                 2049      
                                                                 
=================================================================
Total params: 4,225
Trainable params: 4,225
Non-trainable params: 0
_________________________________________________________________
None
/home/zvd0712/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)
Epoch: 1/50
190/190 - 8s - loss: 0.4544 - accuracy: 0.8306 - val_loss: 0.4703 - val_accuracy: 0.8426 - 8s/epoch - 42ms/step
Epoch: 2/50
190/190 - 7s - loss: 0.4120 - accuracy: 0.8425 - val_loss: 0.4431 - val_accuracy: 0.8443 - 7s/epoch - 39ms/step
Epoch: 3/50
190/190 - 8s - loss: 0.3954 - accuracy: 0.8484 - val_loss: 0.4253 - val_accuracy: 0.8521 - 8s/epoch - 40ms/step
Epoch: 4/50
190/190 - 8s - loss: 0.3829 - accuracy: 0.8556 - val_loss: 0.4143 - val_accuracy: 0.8578 - 8s/epoch - 40ms/step
Epoch: 5/50
190/190 - 8s - loss: 0.3760 - accuracy: 0.8597 - val_loss: 0.4069 - val_accuracy: 0.8623 - 8s/epoch - 40ms/step
Epoch: 6/50
190/190 - 7s - loss: 0.3716 - accuracy: 0.8622 - val_loss: 0.4015 - val_accuracy: 0.8621 - 7s/epoch - 39ms/step
Epoch: 7/50
190/190 - 8s - loss: 0.3673 - accuracy: 0.8640 - val_loss: 0.3946 - val_accuracy: 0.8651 - 8s/epoch - 40ms/step
Epoch: 8/50
190/190 - 8s - loss: 0.3641 - accuracy: 0.8657 - val_loss: 0.3904 - val_accuracy: 0.8655 - 8s/epoch - 39ms/step
Epoch: 9/50
190/190 - 7s - loss: 0.3608 - accuracy: 0.8670 - val_loss: 0.3903 - val_accuracy: 0.8664 - 7s/epoch - 39ms/step
Epoch: 10/50
190/190 - 7s - loss: 0.3578 - accuracy: 0.8674 - val_loss: 0.3868 - val_accuracy: 0.8675 - 7s/epoch - 39ms/step
Epoch: 11/50
190/190 - 8s - loss: 0.3552 - accuracy: 0.8681 - val_loss: 0.3800 - val_accuracy: 0.8674 - 8s/epoch - 40ms/step
Epoch: 12/50
190/190 - 7s - loss: 0.3535 - accuracy: 0.8689 - val_loss: 0.3831 - val_accuracy: 0.8782 - 7s/epoch - 39ms/step
Epoch: 13/50
190/190 - 8s - loss: 0.3501 - accuracy: 0.8696 - val_loss: 0.3761 - val_accuracy: 0.8679 - 8s/epoch - 40ms/step
Epoch: 14/50
190/190 - 7s - loss: 0.3500 - accuracy: 0.8696 - val_loss: 0.3750 - val_accuracy: 0.8681 - 7s/epoch - 39ms/step
Epoch: 15/50
190/190 - 8s - loss: 0.3468 - accuracy: 0.8704 - val_loss: 0.3781 - val_accuracy: 0.8654 - 8s/epoch - 39ms/step
Epoch: 16/50
190/190 - 8s - loss: 0.3467 - accuracy: 0.8704 - val_loss: 0.3725 - val_accuracy: 0.8792 - 8s/epoch - 40ms/step
Epoch: 17/50
190/190 - 8s - loss: 0.3441 - accuracy: 0.8708 - val_loss: 0.3725 - val_accuracy: 0.8789 - 8s/epoch - 40ms/step
Epoch: 18/50
190/190 - 7s - loss: 0.3414 - accuracy: 0.8717 - val_loss: 0.3651 - val_accuracy: 0.8796 - 7s/epoch - 39ms/step
Epoch: 19/50
190/190 - 8s - loss: 0.3380 - accuracy: 0.8726 - val_loss: 0.3644 - val_accuracy: 0.8800 - 8s/epoch - 40ms/step
Epoch: 20/50
190/190 - 8s - loss: 0.3347 - accuracy: 0.8739 - val_loss: 0.3613 - val_accuracy: 0.8796 - 8s/epoch - 40ms/step
Epoch: 21/50
190/190 - 8s - loss: 0.3339 - accuracy: 0.8739 - val_loss: 0.3611 - val_accuracy: 0.8795 - 8s/epoch - 40ms/step
Epoch: 22/50
190/190 - 7s - loss: 0.3337 - accuracy: 0.8746 - val_loss: 0.3602 - val_accuracy: 0.8805 - 7s/epoch - 39ms/step
Epoch: 23/50
190/190 - 8s - loss: 0.3320 - accuracy: 0.8751 - val_loss: 0.3553 - val_accuracy: 0.8809 - 8s/epoch - 40ms/step
Epoch: 24/50
190/190 - 7s - loss: 0.3284 - accuracy: 0.8764 - val_loss: 0.3592 - val_accuracy: 0.8712 - 7s/epoch - 39ms/step
Epoch: 25/50
190/190 - 8s - loss: 0.3261 - accuracy: 0.8773 - val_loss: 0.3486 - val_accuracy: 0.8810 - 8s/epoch - 40ms/step
Epoch: 26/50
190/190 - 8s - loss: 0.3210 - accuracy: 0.8790 - val_loss: 0.3465 - val_accuracy: 0.8714 - 8s/epoch - 40ms/step
Epoch: 27/50
190/190 - 7s - loss: 0.3185 - accuracy: 0.8807 - val_loss: 0.3451 - val_accuracy: 0.8820 - 7s/epoch - 39ms/step
Epoch: 28/50
190/190 - 8s - loss: 0.3162 - accuracy: 0.8824 - val_loss: 0.3445 - val_accuracy: 0.8817 - 8s/epoch - 40ms/step
Epoch: 29/50
190/190 - 8s - loss: 0.3130 - accuracy: 0.8839 - val_loss: 0.3386 - val_accuracy: 0.8814 - 8s/epoch - 40ms/step
Epoch: 30/50
190/190 - 8s - loss: 0.3129 - accuracy: 0.8848 - val_loss: 0.3365 - val_accuracy: 0.8816 - 8s/epoch - 40ms/step
Epoch: 31/50
190/190 - 8s - loss: 0.3022 - accuracy: 0.8896 - val_loss: 0.3334 - val_accuracy: 0.8819 - 8s/epoch - 40ms/step
Epoch: 32/50
190/190 - 7s - loss: 0.3004 - accuracy: 0.8920 - val_loss: 0.3270 - val_accuracy: 0.8820 - 7s/epoch - 39ms/step
Epoch: 33/50
190/190 - 8s - loss: 0.2950 - accuracy: 0.8948 - val_loss: 0.3187 - val_accuracy: 0.8824 - 8s/epoch - 40ms/step
Epoch: 34/50
190/190 - 8s - loss: 0.2947 - accuracy: 0.8961 - val_loss: 0.3231 - val_accuracy: 0.8817 - 8s/epoch - 40ms/step
Epoch: 35/50
190/190 - 8s - loss: 0.2899 - accuracy: 0.8993 - val_loss: 0.3168 - val_accuracy: 0.8841 - 8s/epoch - 40ms/step
Epoch: 36/50
190/190 - 8s - loss: 0.2854 - accuracy: 0.9026 - val_loss: 0.3177 - val_accuracy: 0.9204 - 8s/epoch - 40ms/step
Epoch: 37/50
190/190 - 8s - loss: 0.2843 - accuracy: 0.9049 - val_loss: 0.3103 - val_accuracy: 0.8829 - 8s/epoch - 40ms/step
Epoch: 38/50
190/190 - 8s - loss: 0.2799 - accuracy: 0.9085 - val_loss: 0.3080 - val_accuracy: 0.8858 - 8s/epoch - 39ms/step
Epoch: 39/50
190/190 - 7s - loss: 0.2767 - accuracy: 0.9113 - val_loss: 0.3021 - val_accuracy: 0.9090 - 7s/epoch - 39ms/step
Epoch: 40/50
190/190 - 8s - loss: 0.2755 - accuracy: 0.9130 - val_loss: 0.2962 - val_accuracy: 0.8927 - 8s/epoch - 40ms/step
Epoch: 41/50
190/190 - 8s - loss: 0.2707 - accuracy: 0.9167 - val_loss: 0.2948 - val_accuracy: 0.9361 - 8s/epoch - 40ms/step
Epoch: 42/50
190/190 - 7s - loss: 0.2687 - accuracy: 0.9182 - val_loss: 0.2934 - val_accuracy: 0.9365 - 7s/epoch - 39ms/step
Epoch: 43/50
190/190 - 7s - loss: 0.2628 - accuracy: 0.9219 - val_loss: 0.2878 - val_accuracy: 0.9031 - 7s/epoch - 39ms/step
Epoch: 44/50
190/190 - 7s - loss: 0.2629 - accuracy: 0.9230 - val_loss: 0.2904 - val_accuracy: 0.9031 - 7s/epoch - 39ms/step
Epoch: 45/50
190/190 - 8s - loss: 0.2656 - accuracy: 0.9226 - val_loss: 0.2895 - val_accuracy: 0.9036 - 8s/epoch - 40ms/step
Epoch: 46/50
190/190 - 7s - loss: 0.2613 - accuracy: 0.9255 - val_loss: 0.2785 - val_accuracy: 0.9043 - 7s/epoch - 39ms/step
Epoch: 47/50
190/190 - 7s - loss: 0.2574 - accuracy: 0.9276 - val_loss: 0.2804 - val_accuracy: 0.9304 - 7s/epoch - 39ms/step
Epoch: 48/50
190/190 - 8s - loss: 0.2539 - accuracy: 0.9296 - val_loss: 0.2780 - val_accuracy: 0.9433 - 8s/epoch - 40ms/step
Epoch: 49/50
190/190 - 8s - loss: 0.2514 - accuracy: 0.9310 - val_loss: 0.2806 - val_accuracy: 0.9703 - 8s/epoch - 40ms/step
Epoch: 50/50
190/190 - 8s - loss: 0.2512 - accuracy: 0.9319 - val_loss: 0.2719 - val_accuracy: 0.9671 - 8s/epoch - 40ms/step
1346/1346 [==============================] - 3s 2ms/step
Model: "IDS201X-LUCID"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv0 (Conv2D)              (None, 98, 1, 64)         2176      
                                                                 
 dropout (Dropout)           (None, 98, 1, 64)         0         
                                                                 
 activation (Activation)     (None, 98, 1, 64)         0         
                                                                 
 mp0 (MaxPooling2D)          (None, 1, 1, 64)          0         
                                                                 
 flatten (Flatten)           (None, 64)                0         
                                                                 
 fc1 (Dense)                 (None, 1)                 65        
                                                                 
=================================================================
Total params: 2,241
Trainable params: 2,241
Non-trainable params: 0
_________________________________________________________________
None
/home/zvd0712/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)
Epoch: 1/50
379/379 - 12s - loss: 0.4288 - accuracy: 0.8402 - val_loss: 0.4394 - val_accuracy: 0.8511 - 12s/epoch - 32ms/step
Epoch: 2/50
379/379 - 12s - loss: 0.3905 - accuracy: 0.8537 - val_loss: 0.4248 - val_accuracy: 0.8526 - 12s/epoch - 32ms/step
Epoch: 3/50
379/379 - 12s - loss: 0.3836 - accuracy: 0.8554 - val_loss: 0.4181 - val_accuracy: 0.8549 - 12s/epoch - 32ms/step
Epoch: 4/50
379/379 - 12s - loss: 0.3791 - accuracy: 0.8566 - val_loss: 0.4123 - val_accuracy: 0.8566 - 12s/epoch - 32ms/step
Epoch: 5/50
379/379 - 12s - loss: 0.3741 - accuracy: 0.8584 - val_loss: 0.4100 - val_accuracy: 0.8583 - 12s/epoch - 32ms/step
Epoch: 6/50
379/379 - 12s - loss: 0.3698 - accuracy: 0.8601 - val_loss: 0.4057 - val_accuracy: 0.8596 - 12s/epoch - 32ms/step
Epoch: 7/50
379/379 - 12s - loss: 0.3646 - accuracy: 0.8617 - val_loss: 0.4062 - val_accuracy: 0.8608 - 12s/epoch - 32ms/step
Epoch: 8/50
379/379 - 12s - loss: 0.3594 - accuracy: 0.8629 - val_loss: 0.4041 - val_accuracy: 0.8618 - 12s/epoch - 32ms/step
Epoch: 9/50
379/379 - 12s - loss: 0.3530 - accuracy: 0.8650 - val_loss: 0.4055 - val_accuracy: 0.8663 - 12s/epoch - 32ms/step
Epoch: 10/50
379/379 - 12s - loss: 0.3476 - accuracy: 0.8675 - val_loss: 0.3931 - val_accuracy: 0.8630 - 12s/epoch - 32ms/step
Epoch: 11/50
379/379 - 12s - loss: 0.3420 - accuracy: 0.8709 - val_loss: 0.3963 - val_accuracy: 0.9318 - 12s/epoch - 32ms/step
Epoch: 12/50
379/379 - 12s - loss: 0.3313 - accuracy: 0.8743 - val_loss: 0.4286 - val_accuracy: 0.8101 - 12s/epoch - 32ms/step
Epoch: 13/50
379/379 - 12s - loss: 0.3265 - accuracy: 0.8789 - val_loss: 0.4126 - val_accuracy: 0.8107 - 12s/epoch - 32ms/step
Epoch: 14/50
379/379 - 12s - loss: 0.3206 - accuracy: 0.8840 - val_loss: 0.3815 - val_accuracy: 0.9569 - 12s/epoch - 32ms/step
Epoch: 15/50
379/379 - 12s - loss: 0.3094 - accuracy: 0.8901 - val_loss: 0.3579 - val_accuracy: 0.9543 - 12s/epoch - 32ms/step
Epoch: 16/50
379/379 - 12s - loss: 0.3015 - accuracy: 0.8952 - val_loss: 0.3621 - val_accuracy: 0.9775 - 12s/epoch - 32ms/step
Epoch: 17/50
379/379 - 12s - loss: 0.2981 - accuracy: 0.9001 - val_loss: 0.3541 - val_accuracy: 0.9780 - 12s/epoch - 32ms/step
Epoch: 18/50
379/379 - 12s - loss: 0.2929 - accuracy: 0.9054 - val_loss: 0.3518 - val_accuracy: 0.9594 - 12s/epoch - 32ms/step
Epoch: 19/50
379/379 - 12s - loss: 0.2843 - accuracy: 0.9102 - val_loss: 0.3518 - val_accuracy: 0.9823 - 12s/epoch - 32ms/step
Epoch: 20/50
379/379 - 12s - loss: 0.2811 - accuracy: 0.9145 - val_loss: 0.3424 - val_accuracy: 0.9918 - 12s/epoch - 32ms/step
Epoch: 21/50
379/379 - 12s - loss: 0.2742 - accuracy: 0.9182 - val_loss: 0.3313 - val_accuracy: 0.9923 - 12s/epoch - 32ms/step
Epoch: 22/50
379/379 - 12s - loss: 0.2688 - accuracy: 0.9226 - val_loss: 0.3209 - val_accuracy: 0.9918 - 12s/epoch - 32ms/step
Epoch: 23/50
379/379 - 12s - loss: 0.2636 - accuracy: 0.9251 - val_loss: 0.3411 - val_accuracy: 0.8832 - 12s/epoch - 32ms/step
Epoch: 24/50
379/379 - 12s - loss: 0.2606 - accuracy: 0.9260 - val_loss: 0.3065 - val_accuracy: 0.9921 - 12s/epoch - 32ms/step
Epoch: 25/50
379/379 - 12s - loss: 0.2548 - accuracy: 0.9317 - val_loss: 0.3116 - val_accuracy: 0.9928 - 12s/epoch - 32ms/step
Epoch: 26/50
379/379 - 12s - loss: 0.2508 - accuracy: 0.9329 - val_loss: 0.3043 - val_accuracy: 0.9925 - 12s/epoch - 32ms/step
Epoch: 27/50
379/379 - 12s - loss: 0.2449 - accuracy: 0.9359 - val_loss: 0.3198 - val_accuracy: 0.8845 - 12s/epoch - 32ms/step
Epoch: 28/50
379/379 - 12s - loss: 0.2471 - accuracy: 0.9339 - val_loss: 0.3172 - val_accuracy: 0.9736 - 12s/epoch - 32ms/step
Epoch: 29/50
379/379 - 12s - loss: 0.2422 - accuracy: 0.9374 - val_loss: 0.2934 - val_accuracy: 0.9937 - 12s/epoch - 32ms/step
Epoch: 30/50
379/379 - 12s - loss: 0.2365 - accuracy: 0.9405 - val_loss: 0.2978 - val_accuracy: 0.9851 - 12s/epoch - 32ms/step
Epoch: 31/50
379/379 - 12s - loss: 0.2378 - accuracy: 0.9383 - val_loss: 0.3025 - val_accuracy: 0.9794 - 12s/epoch - 32ms/step
Epoch: 32/50
379/379 - 12s - loss: 0.2312 - accuracy: 0.9422 - val_loss: 0.2807 - val_accuracy: 0.9941 - 12s/epoch - 32ms/step
Epoch: 33/50
379/379 - 12s - loss: 0.2325 - accuracy: 0.9425 - val_loss: 0.2917 - val_accuracy: 0.9867 - 12s/epoch - 32ms/step
Epoch: 34/50
379/379 - 12s - loss: 0.2283 - accuracy: 0.9440 - val_loss: 0.2612 - val_accuracy: 0.9813 - 12s/epoch - 32ms/step
Epoch: 35/50
379/379 - 12s - loss: 0.2285 - accuracy: 0.9433 - val_loss: 0.2806 - val_accuracy: 0.9852 - 12s/epoch - 32ms/step
Epoch: 36/50
379/379 - 12s - loss: 0.2266 - accuracy: 0.9457 - val_loss: 0.3179 - val_accuracy: 0.8489 - 12s/epoch - 32ms/step
Epoch: 37/50
379/379 - 12s - loss: 0.2263 - accuracy: 0.9444 - val_loss: 0.2500 - val_accuracy: 0.9885 - 12s/epoch - 32ms/step
Epoch: 38/50
379/379 - 12s - loss: 0.2196 - accuracy: 0.9478 - val_loss: 0.2471 - val_accuracy: 0.9925 - 12s/epoch - 32ms/step
Epoch: 39/50
379/379 - 12s - loss: 0.2233 - accuracy: 0.9453 - val_loss: 0.2593 - val_accuracy: 0.9937 - 12s/epoch - 32ms/step
Epoch: 40/50
379/379 - 12s - loss: 0.2227 - accuracy: 0.9441 - val_loss: 0.2717 - val_accuracy: 0.9936 - 12s/epoch - 32ms/step
Epoch: 41/50
379/379 - 12s - loss: 0.2233 - accuracy: 0.9445 - val_loss: 0.2591 - val_accuracy: 0.9932 - 12s/epoch - 32ms/step
Epoch: 42/50
379/379 - 12s - loss: 0.2196 - accuracy: 0.9480 - val_loss: 0.2683 - val_accuracy: 0.9940 - 12s/epoch - 32ms/step
Epoch: 43/50
379/379 - 12s - loss: 0.2245 - accuracy: 0.9448 - val_loss: 0.2522 - val_accuracy: 0.9941 - 12s/epoch - 32ms/step
Epoch: 44/50
379/379 - 12s - loss: 0.2283 - accuracy: 0.9453 - val_loss: 0.2478 - val_accuracy: 0.9842 - 12s/epoch - 32ms/step
Epoch: 45/50
379/379 - 12s - loss: 0.2195 - accuracy: 0.9479 - val_loss: 0.2405 - val_accuracy: 0.9905 - 12s/epoch - 32ms/step
Epoch: 46/50
379/379 - 12s - loss: 0.2151 - accuracy: 0.9506 - val_loss: 0.2471 - val_accuracy: 0.9908 - 12s/epoch - 32ms/step
Epoch: 47/50
379/379 - 12s - loss: 0.2133 - accuracy: 0.9510 - val_loss: 0.2336 - val_accuracy: 0.9909 - 12s/epoch - 32ms/step
Epoch: 48/50
379/379 - 12s - loss: 0.2218 - accuracy: 0.9446 - val_loss: 0.2347 - val_accuracy: 0.9844 - 12s/epoch - 32ms/step
Epoch: 49/50
379/379 - 12s - loss: 0.2137 - accuracy: 0.9492 - val_loss: 0.2356 - val_accuracy: 0.9936 - 12s/epoch - 32ms/step
Epoch: 50/50
379/379 - 12s - loss: 0.2101 - accuracy: 0.9504 - val_loss: 0.2492 - val_accuracy: 0.9942 - 12s/epoch - 32ms/step
1346/1346 [==============================] - 3s 2ms/step
Model: "IDS201X-LUCID"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv0 (Conv2D)              (None, 98, 1, 64)         2176      
                                                                 
 dropout (Dropout)           (None, 98, 1, 64)         0         
                                                                 
 activation (Activation)     (None, 98, 1, 64)         0         
                                                                 
 mp0 (MaxPooling2D)          (None, 1, 1, 64)          0         
                                                                 
 flatten (Flatten)           (None, 64)                0         
                                                                 
 fc1 (Dense)                 (None, 1)                 65        
                                                                 
=================================================================
Total params: 2,241
Trainable params: 2,241
Non-trainable params: 0
_________________________________________________________________
None
/home/zvd0712/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super().__init__(name, **kwargs)
Epoch: 1/50
190/190 - 8s - loss: 0.4669 - accuracy: 0.8189 - val_loss: 0.4888 - val_accuracy: 0.8403 - 8s/epoch - 41ms/step
Epoch: 2/50
190/190 - 7s - loss: 0.4194 - accuracy: 0.8426 - val_loss: 0.4552 - val_accuracy: 0.8491 - 7s/epoch - 38ms/step
Epoch: 3/50
190/190 - 7s - loss: 0.4054 - accuracy: 0.8476 - val_loss: 0.4394 - val_accuracy: 0.8513 - 7s/epoch - 38ms/step
Epoch: 4/50
190/190 - 7s - loss: 0.3973 - accuracy: 0.8499 - val_loss: 0.4295 - val_accuracy: 0.8530 - 7s/epoch - 39ms/step
Epoch: 5/50
190/190 - 7s - loss: 0.3918 - accuracy: 0.8518 - val_loss: 0.4273 - val_accuracy: 0.8532 - 7s/epoch - 39ms/step
Epoch: 6/50
190/190 - 7s - loss: 0.3875 - accuracy: 0.8536 - val_loss: 0.4251 - val_accuracy: 0.8554 - 7s/epoch - 38ms/step
Epoch: 7/50
190/190 - 7s - loss: 0.3834 - accuracy: 0.8552 - val_loss: 0.4238 - val_accuracy: 0.8555 - 7s/epoch - 38ms/step
Epoch: 8/50
190/190 - 7s - loss: 0.3796 - accuracy: 0.8563 - val_loss: 0.4155 - val_accuracy: 0.8575 - 7s/epoch - 38ms/step
Epoch: 9/50
190/190 - 7s - loss: 0.3765 - accuracy: 0.8575 - val_loss: 0.4166 - val_accuracy: 0.8583 - 7s/epoch - 38ms/step
Epoch: 10/50
190/190 - 7s - loss: 0.3740 - accuracy: 0.8586 - val_loss: 0.4096 - val_accuracy: 0.8585 - 7s/epoch - 38ms/step
Epoch: 11/50
190/190 - 7s - loss: 0.3696 - accuracy: 0.8598 - val_loss: 0.4048 - val_accuracy: 0.8590 - 7s/epoch - 39ms/step
Epoch: 12/50
190/190 - 7s - loss: 0.3665 - accuracy: 0.8606 - val_loss: 0.4033 - val_accuracy: 0.8603 - 7s/epoch - 39ms/step
Epoch: 13/50
190/190 - 7s - loss: 0.3624 - accuracy: 0.8616 - val_loss: 0.4094 - val_accuracy: 0.8580 - 7s/epoch - 38ms/step
Epoch: 14/50
190/190 - 7s - loss: 0.3605 - accuracy: 0.8622 - val_loss: 0.4104 - val_accuracy: 0.8617 - 7s/epoch - 38ms/step
Epoch: 15/50
190/190 - 7s - loss: 0.3563 - accuracy: 0.8631 - val_loss: 0.4160 - val_accuracy: 0.9229 - 7s/epoch - 38ms/step
Epoch: 16/50
190/190 - 7s - loss: 0.3537 - accuracy: 0.8644 - val_loss: 0.4091 - val_accuracy: 0.9215 - 7s/epoch - 38ms/step
Epoch: 17/50
190/190 - 7s - loss: 0.3486 - accuracy: 0.8656 - val_loss: 0.4046 - val_accuracy: 0.8923 - 7s/epoch - 38ms/step
Epoch: 18/50
190/190 - 7s - loss: 0.3431 - accuracy: 0.8667 - val_loss: 0.3917 - val_accuracy: 0.8638 - 7s/epoch - 38ms/step
Epoch: 19/50
190/190 - 7s - loss: 0.3383 - accuracy: 0.8684 - val_loss: 0.3935 - val_accuracy: 0.8656 - 7s/epoch - 38ms/step
Epoch: 20/50
190/190 - 7s - loss: 0.3346 - accuracy: 0.8709 - val_loss: 0.4014 - val_accuracy: 0.9372 - 7s/epoch - 39ms/step
Epoch: 21/50
190/190 - 7s - loss: 0.3291 - accuracy: 0.8728 - val_loss: 0.3986 - val_accuracy: 0.9416 - 7s/epoch - 38ms/step
Epoch: 22/50
190/190 - 7s - loss: 0.3252 - accuracy: 0.8755 - val_loss: 0.3868 - val_accuracy: 0.9444 - 7s/epoch - 38ms/step
Epoch: 23/50
190/190 - 7s - loss: 0.3220 - accuracy: 0.8793 - val_loss: 0.3867 - val_accuracy: 0.9466 - 7s/epoch - 38ms/step
Epoch: 24/50
190/190 - 7s - loss: 0.3181 - accuracy: 0.8821 - val_loss: 0.3906 - val_accuracy: 0.8475 - 7s/epoch - 38ms/step
Epoch: 25/50
190/190 - 7s - loss: 0.3145 - accuracy: 0.8852 - val_loss: 0.3750 - val_accuracy: 0.9560 - 7s/epoch - 38ms/step
Epoch: 26/50
190/190 - 7s - loss: 0.3084 - accuracy: 0.8887 - val_loss: 0.3692 - val_accuracy: 0.9518 - 7s/epoch - 38ms/step
Epoch: 27/50
190/190 - 7s - loss: 0.3046 - accuracy: 0.8928 - val_loss: 0.3577 - val_accuracy: 0.9472 - 7s/epoch - 38ms/step
Epoch: 28/50
190/190 - 7s - loss: 0.2996 - accuracy: 0.8958 - val_loss: 0.3516 - val_accuracy: 0.9505 - 7s/epoch - 38ms/step
Epoch: 29/50
190/190 - 7s - loss: 0.2953 - accuracy: 0.8990 - val_loss: 0.3535 - val_accuracy: 0.9564 - 7s/epoch - 38ms/step
Epoch: 30/50
190/190 - 7s - loss: 0.2928 - accuracy: 0.9027 - val_loss: 0.3488 - val_accuracy: 0.9560 - 7s/epoch - 38ms/step
Epoch: 31/50
190/190 - 7s - loss: 0.2950 - accuracy: 0.9033 - val_loss: 0.3839 - val_accuracy: 0.8124 - 7s/epoch - 38ms/step
Epoch: 32/50
190/190 - 7s - loss: 0.2855 - accuracy: 0.9075 - val_loss: 0.3336 - val_accuracy: 0.9552 - 7s/epoch - 39ms/step
Epoch: 33/50
190/190 - 7s - loss: 0.2812 - accuracy: 0.9107 - val_loss: 0.3524 - val_accuracy: 0.9482 - 7s/epoch - 39ms/step
Epoch: 34/50
190/190 - 7s - loss: 0.2853 - accuracy: 0.9101 - val_loss: 0.3643 - val_accuracy: 0.8201 - 7s/epoch - 38ms/step
Epoch: 35/50
190/190 - 7s - loss: 0.2717 - accuracy: 0.9177 - val_loss: 0.3229 - val_accuracy: 0.9879 - 7s/epoch - 38ms/step
Epoch: 36/50
190/190 - 7s - loss: 0.2722 - accuracy: 0.9183 - val_loss: 0.3311 - val_accuracy: 0.9794 - 7s/epoch - 38ms/step
Epoch: 37/50
190/190 - 7s - loss: 0.2660 - accuracy: 0.9211 - val_loss: 0.3383 - val_accuracy: 0.9681 - 7s/epoch - 38ms/step
Epoch: 38/50
190/190 - 7s - loss: 0.2609 - accuracy: 0.9255 - val_loss: 0.3108 - val_accuracy: 0.9879 - 7s/epoch - 38ms/step
Epoch: 39/50
190/190 - 7s - loss: 0.2663 - accuracy: 0.9236 - val_loss: 0.3283 - val_accuracy: 0.9915 - 7s/epoch - 38ms/step
Epoch: 40/50
190/190 - 7s - loss: 0.2607 - accuracy: 0.9267 - val_loss: 0.3357 - val_accuracy: 0.9733 - 7s/epoch - 38ms/step
Epoch: 41/50
190/190 - 7s - loss: 0.2537 - accuracy: 0.9313 - val_loss: 0.2959 - val_accuracy: 0.9878 - 7s/epoch - 38ms/step
Epoch: 42/50
190/190 - 7s - loss: 0.2622 - accuracy: 0.9267 - val_loss: 0.3217 - val_accuracy: 0.9798 - 7s/epoch - 38ms/step
Epoch: 43/50
190/190 - 7s - loss: 0.2503 - accuracy: 0.9332 - val_loss: 0.2903 - val_accuracy: 0.9850 - 7s/epoch - 39ms/step
Epoch: 44/50
190/190 - 7s - loss: 0.2510 - accuracy: 0.9340 - val_loss: 0.3103 - val_accuracy: 0.9619 - 7s/epoch - 38ms/step
Epoch: 45/50
190/190 - 7s - loss: 0.2634 - accuracy: 0.9266 - val_loss: 0.2943 - val_accuracy: 0.9907 - 7s/epoch - 38ms/step
Epoch: 46/50
190/190 - 7s - loss: 0.2400 - accuracy: 0.9394 - val_loss: 0.2901 - val_accuracy: 0.9914 - 7s/epoch - 38ms/step
Epoch: 47/50
190/190 - 7s - loss: 0.2493 - accuracy: 0.9338 - val_loss: 0.2790 - val_accuracy: 0.9848 - 7s/epoch - 38ms/step
Epoch: 48/50
190/190 - 7s - loss: 0.2466 - accuracy: 0.9336 - val_loss: 0.2801 - val_accuracy: 0.9898 - 7s/epoch - 38ms/step
Epoch: 49/50
190/190 - 7s - loss: 0.2452 - accuracy: 0.9343 - val_loss: 0.2893 - val_accuracy: 0.9937 - 7s/epoch - 38ms/step
Epoch: 50/50
190/190 - 7s - loss: 0.2320 - accuracy: 0.9445 - val_loss: 0.3092 - val_accuracy: 0.9815 - 7s/epoch - 38ms/step
1346/1346 [==============================] - 3s 3ms/step

#test prediction
!python3 lucid_cnn.py --predict ./cic-processed-data/ --model ./cic-processed-data/100t-100n-IDS201X-LUCID.h5

2022-11-13 00:46:59.139651: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-13 00:46:59.241532: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-11-13 00:46:59.263918: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-13 00:46:59.746328: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-13 00:46:59.746388: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-13 00:46:59.746395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2022-11-13 00:47:00.673054: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
20

22-11-13 00:47:00.673097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ws103a-z41387
2022-11-13 00:47:00.673107: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ws103a-z41387
2022-11-13 00:47:00.673256: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 520.61.5
2022-11-13 00:47:00.673284: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5
2022-11-13 00:47:00.673293: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 520.61.5
2022-11-13 00:47:00.673625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
43/43 [==============================] - 1s 19ms/step
43/43 [==============================] - 1s 19ms/step
Model         TIME(sec) PACKETS SAMPLES DDOS% ACC    ERR    F1     PPV    TPR    FPR    TNR    FNR    Data Source
IDS201X-LUCID     1.086 0653940 0087259 0.502 0.9942 0.2019 0.9942 0.9920 0.9963 0.0080 0.9920 0.0037 100t-100n-IDS201X-dataset-test.hdf5

 

 


